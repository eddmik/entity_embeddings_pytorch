{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ! ssh -L 8888:localhost:8888 edd@192.168.1.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:39:29.685524Z",
     "start_time": "2019-03-24T13:39:29.680799Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! kaggle competitions download -c house-prices-advanced-regression-techniques\n",
    "# ! mkdir data\n",
    "# ! mv *.txt data/\n",
    "# ! mv *.csv data/\n",
    "# ! ls ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Neural Network in PyTorch for Tabular Data with Categorical Embeddings\n",
    "\n",
    "- https://www.fast.ai/2018/04/29/categorical-embeddings/\n",
    "- https://yashuseth.blog/2018/07/22/pytorch-neural-network-for-tabular-data-with-categorical-embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:39:49.614710Z",
     "start_time": "2019-03-24T13:39:49.455630Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, data, cat_cols=None, output_col=None):\n",
    "        \"\"\"\n",
    "    Characterizes a Dataset for PyTorch\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data: pandas data frame\n",
    "      The data frame object for the input data. It must\n",
    "      contain all the continuous, categorical and the\n",
    "      output columns to be used.\n",
    "\n",
    "    cat_cols: List of strings\n",
    "      The names of the categorical columns in the data.\n",
    "      These columns will be passed through the embedding\n",
    "      layers in the model. These columns must be\n",
    "      label encoded beforehand. \n",
    "\n",
    "    output_col: string\n",
    "      The name of the output variable column in the data\n",
    "      provided.\n",
    "    \"\"\"\n",
    "\n",
    "        self.n = data.shape[0]\n",
    "\n",
    "        if output_col:\n",
    "            self.y = data[output_col].astype(np.float32).values.reshape(-1, 1)\n",
    "        else:\n",
    "            self.y = np.zeros((self.n, 1))\n",
    "\n",
    "        self.cat_cols = cat_cols if cat_cols else []\n",
    "        self.cont_cols = [\n",
    "            col for col in data.columns\n",
    "            if col not in self.cat_cols + [output_col]\n",
    "        ]\n",
    "\n",
    "        if self.cont_cols:\n",
    "            self.cont_X = data[self.cont_cols].astype(np.float32).values\n",
    "        else:\n",
    "            self.cont_X = np.zeros((self.n, 1))\n",
    "\n",
    "        if self.cat_cols:\n",
    "            self.cat_X = data[cat_cols].astype(np.int64).values\n",
    "        else:\n",
    "            self.cat_X = np.zeros((self.n, 1))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "    Denotes the total number of samples.\n",
    "    \"\"\"\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "    Generates one sample of data.\n",
    "    \"\"\"\n",
    "        return [self.y[idx], self.cont_X[idx], self.cat_X[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:39:49.692427Z",
     "start_time": "2019-03-24T13:39:49.618242Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, emb_dims, no_of_cont, lin_layer_sizes, output_size,\n",
    "                 emb_dropout, lin_layer_dropouts):\n",
    "        \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    emb_dims: List of two element tuples\n",
    "      This list will contain a two element tuple for each\n",
    "      categorical feature. The first element of a tuple will\n",
    "      denote the number of unique values of the categorical\n",
    "      feature. The second element will denote the embedding\n",
    "      dimension to be used for that feature.\n",
    "\n",
    "    no_of_cont: Integer\n",
    "      The number of continuous features in the data.\n",
    "\n",
    "    lin_layer_sizes: List of integers.\n",
    "      The size of each linear layer. The length will be equal\n",
    "      to the total number\n",
    "      of linear layers in the network.\n",
    "\n",
    "    output_size: Integer\n",
    "      The size of the final output.\n",
    "\n",
    "    emb_dropout: Float\n",
    "      The dropout to be used after the embedding layers.\n",
    "\n",
    "    lin_layer_dropouts: List of floats\n",
    "      The dropouts to be used after each linear layer.\n",
    "    \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding layers\n",
    "        self.emb_layers = nn.ModuleList(\n",
    "            [nn.Embedding(x, y) for x, y in emb_dims])\n",
    "\n",
    "        no_of_embs = sum([y for x, y in emb_dims])\n",
    "        self.no_of_embs = no_of_embs\n",
    "        self.no_of_cont = no_of_cont\n",
    "\n",
    "        # Linear Layers\n",
    "        first_lin_layer = nn.Linear(self.no_of_embs + self.no_of_cont,\n",
    "                                    lin_layer_sizes[0])\n",
    "\n",
    "        self.lin_layers =\\\n",
    "         nn.ModuleList([first_lin_layer] +\\\n",
    "              [nn.Linear(lin_layer_sizes[i], lin_layer_sizes[i + 1])\n",
    "               for i in range(len(lin_layer_sizes) - 1)])\n",
    "\n",
    "        for lin_layer in self.lin_layers:\n",
    "            nn.init.kaiming_normal_(lin_layer.weight.data)\n",
    "\n",
    "        # Output Layer\n",
    "        self.output_layer = nn.Linear(lin_layer_sizes[-1], output_size)\n",
    "        nn.init.kaiming_normal_(self.output_layer.weight.data)\n",
    "\n",
    "        # Batch Norm Layers\n",
    "        self.first_bn_layer = nn.BatchNorm1d(self.no_of_cont)\n",
    "        self.bn_layers = nn.ModuleList(\n",
    "            [nn.BatchNorm1d(size) for size in lin_layer_sizes])\n",
    "\n",
    "        # Dropout Layers\n",
    "        self.emb_dropout_layer = nn.Dropout(emb_dropout)\n",
    "        self.droput_layers = nn.ModuleList(\n",
    "            [nn.Dropout(size) for size in lin_layer_dropouts])\n",
    "\n",
    "    def forward(self, cont_data, cat_data):\n",
    "\n",
    "        if self.no_of_embs != 0:\n",
    "            x = [\n",
    "                emb_layer(cat_data[:, i])\n",
    "                for i, emb_layer in enumerate(self.emb_layers)\n",
    "            ]\n",
    "            x = torch.cat(x, 1)\n",
    "            x = self.emb_dropout_layer(x)\n",
    "\n",
    "        if self.no_of_cont != 0:\n",
    "            normalized_cont_data = self.first_bn_layer(cont_data)\n",
    "\n",
    "            if self.no_of_embs != 0:\n",
    "                x = torch.cat([x, normalized_cont_data], 1)\n",
    "            else:\n",
    "                x = normalized_cont_data\n",
    "\n",
    "        for lin_layer, dropout_layer, bn_layer in\\\n",
    "            zip(self.lin_layers, self.droput_layers, self.bn_layers):\n",
    "\n",
    "            x = F.relu(lin_layer(x))\n",
    "            x = bn_layer(x)\n",
    "            x = dropout_layer(x)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:39:49.916575Z",
     "start_time": "2019-03-24T13:39:49.695820Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Using only a subset of the variables.\n",
    "data = pd.read_csv(\n",
    "    \"./data/train.csv\",\n",
    "    usecols=[\n",
    "        \"SalePrice\", \"MSSubClass\", \"MSZoning\", \"LotFrontage\", \"LotArea\",\n",
    "        \"Street\", \"YearBuilt\", \"LotShape\", \"1stFlrSF\", \"2ndFlrSF\"\n",
    "    ]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:39:49.940698Z",
     "start_time": "2019-03-24T13:39:49.929750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>2003</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1976</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2001</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1915</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2000</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  YearBuilt  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg       2003   \n",
       "1          20       RL         80.0     9600   Pave      Reg       1976   \n",
       "2          60       RL         68.0    11250   Pave      IR1       2001   \n",
       "3          70       RL         60.0     9550   Pave      IR1       1915   \n",
       "4          60       RL         84.0    14260   Pave      IR1       2000   \n",
       "\n",
       "   1stFlrSF  2ndFlrSF  SalePrice  \n",
       "0       856       854     208500  \n",
       "1      1262         0     181500  \n",
       "2       920       866     223500  \n",
       "3       961       756     140000  \n",
       "4      1145      1053     250000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:39:50.203230Z",
     "start_time": "2019-03-24T13:39:49.951176Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    \"MSSubClass\", \"MSZoning\", \"Street\", \"LotShape\", \"YearBuilt\"\n",
    "]\n",
    "output_feature = \"SalePrice\"\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoders = {}\n",
    "for cat_col in categorical_features:\n",
    "    label_encoders[cat_col] = LabelEncoder()\n",
    "    data[cat_col] = label_encoders[cat_col].fit_transform(data[cat_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:39:50.217310Z",
     "start_time": "2019-03-24T13:39:50.214517Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = TabularDataset(\n",
    "    data=data, cat_cols=categorical_features, output_col=output_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:39:50.229389Z",
     "start_time": "2019-03-24T13:39:50.227235Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "dataloader = DataLoader(dataset, batchsize, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:39:50.241768Z",
     "start_time": "2019-03-24T13:39:50.239144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 5, 2, 4, 112]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dims = [int(data[col].nunique()) for col in categorical_features]\n",
    "cat_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:39:50.253849Z",
     "start_time": "2019-03-24T13:39:50.251498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15, 8), (5, 3), (2, 1), (4, 2), (112, 50)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dims = [(x, min(50, (x + 1) // 2)) for x in cat_dims]\n",
    "emb_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:40:10.695028Z",
     "start_time": "2019-03-24T13:40:08.718516Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FeedForwardNN(\n",
    "    emb_dims,\n",
    "    no_of_cont=4,\n",
    "    lin_layer_sizes=[50, 100],\n",
    "    output_size=1,\n",
    "    emb_dropout=0.04,\n",
    "    lin_layer_dropouts=[0.001, 0.01]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:42:28.543332Z",
     "start_time": "2019-03-24T13:42:28.189349Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_of_epochs = 5\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "for epoch in range(no_of_epochs):\n",
    "    for y, cont_x, cat_x in dataloader:\n",
    "        cat_x = cat_x.to(device)\n",
    "        cont_x = cont_x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Forward Pass\n",
    "        preds = model(cont_x, cat_x)\n",
    "        loss = criterion(preds, y)\n",
    "\n",
    "        # Backward Pass and Optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
